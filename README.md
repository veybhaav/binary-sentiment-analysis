ğŸŒŸ Binary Sentiment Analysis Microservice

A fully containerized, end-to-end microservice for binary sentiment analysis using a Hugging Face Transformer model. Includes:

Python FastAPI backend for inference

Standalone fine-tuning script

React frontend UI

Docker Compose setup for local deployment

ğŸŒ Demo Screenshots

(You can optionally embed demo video or screenshots here)



ğŸ“Š Project Structure

binary-sentiment-analysis/
â”œâ”€â”€ app/                       # Backend API
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ model_loader.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/                 # React Frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ model/                    # Saved fine-tuned model (ignored in Git)
â”œâ”€â”€ data.jsonl                # Fine-tuning dataset
â”œâ”€â”€ finetune.py               # Model fine-tuning script
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile (backend)
â”œâ”€â”€ frontend.Dockerfile       # Dockerfile for React app
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

ğŸ“… Prerequisites

Docker Desktop (Windows/Linux/macOS)

Python 3.8+

Node.js & npm (if running frontend outside Docker)

ğŸ§± Setup & Run Instructions

1. Clone the Repository

git clone https://github.com/your-username/binary-sentiment-analysis.git
cd binary-sentiment-analysis

2. Build & Run with Docker Compose

docker compose up --build

Backend: http://localhost:8000

Frontend: http://localhost:3000

ğŸ” API Documentation

POST /predict

Description: Returns the sentiment prediction

Request Body:

{
  "text": "I love this!"
}

Response:

{
  "label": "positive",
  "score": 0.9876
}

ğŸ”§ Fine-Tuning

Dataset Format: data.jsonl

{"text": "Great product!", "label": "positive"}
{"text": "Worst experience ever.", "label": "negative"}

Run Fine-Tuning Script

python finetune.py --data data.jsonl --epochs 3 --lr 3e-5

Saves model to ./model/

Automatically picked up by backend on restart

ğŸ¨ Frontend UI

Features:

Text area input

Predict button

Shows label and score

Access the UI at: http://localhost:3000

ğŸš€ Deployment

Deploy Frontend to Vercel

Push your project to GitHub

Go to vercel.com > Import Project > Link GitHub repo

Set root to frontend/ and framework to React

Deploy

Deploy Backend to Render

Zip only the app/, model/, and Dockerfile

Go to render.com

Create a new Web Service from GitHub or zip

Set build command: pip install -r requirements.txt

Start command: uvicorn app:app --host 0.0.0.0 --port 8000

Choose free instance (CPU-only)

ğŸ“… Model Notes

Base model: distilbert-base-uncased

Can be fine-tuned on any binary sentiment dataset

Uses PyTorch by default

âš ï¸ Models over 100MB should be excluded from Git via .gitignore:

model/
*.pt
*.safetensors

ğŸŒŸ Optional Enhancements

Live typing inference

GraphQL API support

Async batch inference

Model quantization (ONNX / bitsandbytes)

TypeScript React frontend

GitHub Actions CI/CD pipeline

ğŸ“ˆ Performance

Device

Training Time (3 Epochs)

Inference Time

CPU

~2 min

~200ms

GPU (T4)

~15 sec

~40ms

ğŸ™ Credits

Built by Vaibhav Jaitwal
MIT License

ğŸ“ Local Development Commands (optional)

# Run backend without Docker
cd app
uvicorn app:app --reload --port 8000

# Run frontend without Docker
cd frontend
npm install
npm start

ğŸš« Troubleshooting

CORS Error: Ensure http://localhost:3000 is allowed in backend CORS middleware.

Large file error: Use Git LFS or add to .gitignore.

White screen: Check frontend/src/index.js is present and correctly importing App.jsx.
